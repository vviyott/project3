# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import streamlit as st
import os
import json
import numpy as np
import urllib.request
import urllib.parse
import re
import pandas as pd
from datetime import datetime
from supabase import create_client
from openai import OpenAI
from sentence_transformers import SentenceTransformer
import torch
import time

# í˜ì´ì§€ êµ¬ì„±
st.set_page_config(page_title="ìŠ¤ë§ˆíŠ¸ ì‡¼í•‘ íŒŒì¸ë”", layout="wide")

# ë„¤ì´ë²„ API í´ë¼ì´ì–¸íŠ¸ IDì™€ ì‹œí¬ë¦¿
NAVER_CLIENT_ID = "qUdRFUYQv27dI6GZr4Wz"
NAVER_CLIENT_SECRET = "HWYWOFBEYH"

# Streamlitì—ì„œ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ê³  secrets ê°€ì ¸ì˜¤ê¸°
try:
    # Streamlit Cloud í™˜ê²½ì—ì„œëŠ” st.secrets ì‚¬ìš©
    supabase_url = st.secrets["SUPABASE_URL"]
    supabase_key = st.secrets["SUPABASE_KEY"]
    openai_api_key = st.secrets["OPENAI_API_KEY"]
except Exception as e:
    # ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©
    try:
        import dotenv
        dotenv.load_dotenv()
        supabase_url = os.environ.get("SUPABASE_URL")
        supabase_key = os.environ.get("SUPABASE_KEY")
        openai_api_key = os.environ.get("OPENAI_API_KEY")
    except:
        st.error("API í‚¤ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë‚˜ Streamlit Secretsê°€ ì œëŒ€ë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

# API í‚¤ í™•ì¸
if not supabase_url or not supabase_key or not openai_api_key:
    st.error("í•„ìš”í•œ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (OpenAIëŠ” ë‹µë³€ ìƒì„±ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤)")
    st.stop()

# Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    supabase = create_client(supabase_url, supabase_key)
    st.sidebar.success("Supabase ì—°ê²° ì„±ê³µ!")
except Exception as e:
    st.error(f"Supabase ì—°ê²° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    st.stop()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (GPT ë‹µë³€ ìƒì„±ìš©)
try:
    openai_client = OpenAI(api_key=openai_api_key)
    st.sidebar.success("OpenAI ì—°ê²° ì„±ê³µ!")
except Exception as e:
    st.error(f"OpenAI ì—°ê²° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    st.stop()

# ë¬´ë£Œ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
@st.cache_resource
def load_embedding_model():
    """í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë”© (ìºì‹œë¨)"""
    try:
        # í•œêµ­ì–´ ì„±ëŠ¥ì´ ì¢‹ì€ ë¬´ë£Œ ëª¨ë¸
        model = SentenceTransformer('jhgan/ko-sroberta-multitask')
        st.sidebar.success("ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì„±ê³µ!")
        return model
    except Exception as e:
        st.sidebar.error(f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        # ë°±ì—… ëª¨ë¸ ì‚¬ìš©
        try:
            model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            st.sidebar.warning("ë°±ì—… ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© ì¤‘")
            return model
        except Exception as e2:
            st.error(f"ë°±ì—… ëª¨ë¸ë„ ë¡œë”© ì‹¤íŒ¨: {str(e2)}")
            st.stop()

# ì„ë² ë”© ëª¨ë¸ ë¡œë”©
embedding_model = load_embedding_model()

def test_naver_api():
    """ë„¤ì´ë²„ API ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        test_query = "í…ŒìŠ¤íŠ¸"
        encoded_query = urllib.parse.quote(test_query)
        url = f"https://openapi.naver.com/v1/search/blog?query={encoded_query}&display=1"
        
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
        request.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
        request.add_header("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
        
        response = urllib.request.urlopen(request, timeout=10)
        return response.getcode() == 200
    except Exception as e:
        st.sidebar.error(f"ë„¤ì´ë²„ API í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False

# ë„¤ì´ë²„ API ìƒíƒœ í™•ì¸
if test_naver_api():
    st.sidebar.success("ë„¤ì´ë²„ API ì—°ê²° ì„±ê³µ!")
else:
    st.sidebar.error("ë„¤ì´ë²„ API ì—°ê²° ì‹¤íŒ¨!")

def generate_embedding(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ë¬´ë£Œ ì„ë² ë”© ìƒì„± - ê°œì„ ëœ ë²„ì „"""
    try:
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì¶”ê°€
        if not text or len(text.strip()) < 10:  # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ ì œì™¸
            return None
        
        # í…ìŠ¤íŠ¸ ì •ê·œí™” ê°•í™”
        cleaned_text = re.sub(r'\s+', ' ', text.strip())            # ê³µë°± ì •ê·œí™”
        cleaned_text = re.sub(r'[^\w\sê°€-í£\.]', ' ', cleaned_text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ë§ˆì¹¨í‘œëŠ” ìœ ì§€)
        cleaned_text = ' '.join(cleaned_text.split())               # ì¤‘ë³µ ê³µë°± ì œê±°
        
        # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ëŠ” ì˜ë¼ë‚´ê¸° (ëª¨ë¸ ì œí•œ ê³ ë ¤)
        if len(cleaned_text) > 512:  # sentence-transformers ì¼ë°˜ì  ì œí•œ
            cleaned_text = cleaned_text[:512]
        
        # ë¬´ë£Œ ì„ë² ë”© ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„±
        embedding = embedding_model.encode(cleaned_text, convert_to_tensor=False)
        
        # numpy arrayë¥¼ listë¡œ ë³€í™˜
        if hasattr(embedding, 'tolist'):
            embedding_list = embedding.tolist()
        else:
            embedding_list = embedding
        
        # 768ì°¨ì›ì„ 1536ì°¨ì›ìœ¼ë¡œ íŒ¨ë”© (0ìœ¼ë¡œ ì±„ì›€)
        if len(embedding_list) == 768:
            # 0ìœ¼ë¡œ íŒ¨ë”©í•˜ì—¬ 1536ì°¨ì›ìœ¼ë¡œ ë§Œë“¤ê¸°
            padded_embedding = embedding_list + [0.0] * (1536 - 768)
            return padded_embedding
        elif len(embedding_list) == 1536:
            return embedding_list
        else:
            st.warning(f"ì˜ˆìƒì¹˜ ëª»í•œ ì„ë² ë”© ì°¨ì›: {len(embedding_list)}")
            # 1536ì°¨ì›ìœ¼ë¡œ ë§ì¶”ê¸°
            if len(embedding_list) < 1536:
                return embedding_list + [0.0] * (1536 - len(embedding_list))
            else:
                return embedding_list[:1536]
            
    except Exception as e:
        st.error(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise

def search_naver_api(query, source_type, count=20):
    """ë„¤ì´ë²„ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰í•˜ê³  ê²°ê³¼ë¥¼ Supabaseì— ì €ì¥ - ê°œì„ ëœ ë²„ì „"""
    try:
        # ì†ŒìŠ¤ íƒ€ì…ì— ë”°ë¥¸ API ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
        if source_type == "ë¸”ë¡œê·¸":
            api_endpoint = "blog"
        elif source_type == "ë‰´ìŠ¤":
            api_endpoint = "news"
        elif source_type == "ì‡¼í•‘":
            api_endpoint = "shop"
        else:
            api_endpoint = "blog"  # ê¸°ë³¸ê°’
        
        # ì¿¼ë¦¬ ì¸ì½”ë”©
        encoded_query = urllib.parse.quote(query)
        url = f"https://openapi.naver.com/v1/search/{api_endpoint}?query={encoded_query}&display={count}&sort=sim"
        
        # ìš”ì²­ í—¤ë” ì„¤ì • (ê°œì„ )
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
        request.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
        request.add_header("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
        
        # API ìš”ì²­ ë° ì‘ë‹µ ì²˜ë¦¬ (ê°œì„ ëœ ì˜ˆì™¸ ì²˜ë¦¬)
        try:
            response = urllib.request.urlopen(request, timeout=15)
            response_code = response.getcode()
            
            if response_code == 200:
                # ì‘ë‹µ ì½ê¸°
                response_body = response.read()
                
                # ì‘ë‹µì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
                if not response_body:
                    st.error("ë„¤ì´ë²„ APIì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
                    return [], 0, 0
                
                # ë””ì½”ë”© ë° JSON íŒŒì‹± (ê°œì„ ëœ ì˜¤ë¥˜ ì²˜ë¦¬)
                try:
                    response_text = response_body.decode('utf-8')
                    
                    # ë””ë²„ê¹…: ì‘ë‹µ ë‚´ìš©ì˜ ì‹œì‘ ë¶€ë¶„ í™•ì¸
                    if not response_text.strip().startswith('{'):
                        st.error(f"ìœ íš¨í•˜ì§€ ì•Šì€ JSON ì‘ë‹µ: {response_text[:200]}...")
                        return [], 0, 0
                    
                    response_data = json.loads(response_text)
                    
                except json.JSONDecodeError as e:
                    st.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                    st.error(f"ì‘ë‹µ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {response_text[:200] if 'response_text' in locals() else 'ë””ì½”ë”© ì‹¤íŒ¨'}...")
                    return [], 0, 0
                except UnicodeDecodeError as e:
                    st.error(f"ì‘ë‹µ ë””ì½”ë”© ì˜¤ë¥˜: {str(e)}")
                    return [], 0, 0
                
                # ì‘ë‹µ ë°ì´í„° í™•ì¸
                if 'items' not in response_data:
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    return [], 0, 0
                
                # ê²°ê³¼ ì²˜ë¦¬ ë° Supabaseì— ì €ì¥
                saved_count = 0
                items = response_data.get('items', [])
                
                for i, item in enumerate(items):
                    try:
                        # HTML íƒœê·¸ ì œê±°
                        title = re.sub('<[^<]+?>', '', item.get('title', '')) if item.get('title') else 'ì œëª© ì—†ìŒ'
                        
                        # ì†ŒìŠ¤ íƒ€ì…ì— ë”°ë¥¸ ë‚´ìš© í•„ë“œ ì¶”ì¶œ ë° ê°œì„ ëœ í…ìŠ¤íŠ¸ êµ¬ì„±
                        if source_type == "ë¸”ë¡œê·¸":
                            content = re.sub('<[^<]+?>', '', item.get('description', '')) if item.get('description') else ''
                            metadata = {
                                'title': title,
                                'url': item.get('link', ''),
                                'bloggername': item.get('bloggername', ''),
                                'date': item.get('postdate', ''),
                                'collection': source_type
                            }
                            # ê°œì„ ëœ ì „ì²´ í…ìŠ¤íŠ¸ êµ¬ì„±
                            full_text = f"ì œëª©: {title}\në‚´ìš©: {content}\në¸”ë¡œê±°: {metadata.get('bloggername', '')}\nì¹´í…Œê³ ë¦¬: ë¸”ë¡œê·¸"
                            
                        elif source_type == "ë‰´ìŠ¤":
                            content = re.sub('<[^<]+?>', '', item.get('description', '')) if item.get('description') else ''
                            # ê°„ë‹¨í•œ ë‚ ì§œ ì²˜ë¦¬
                            pub_date = item.get('pubDate', '')
                            
                            metadata = {
                                'title': title,
                                'url': item.get('link', ''),
                                'publisher': item.get('originallink', '').replace('https://', '').replace('http://', '').split('/')[0] if item.get('originallink') else '',
                                'date': pub_date,
                                'collection': source_type
                            }
                            # ê°œì„ ëœ ì „ì²´ í…ìŠ¤íŠ¸ êµ¬ì„± - ë‰´ìŠ¤ì— ë§ê²Œ ìˆ˜ì •
                            full_text = f"ë‰´ìŠ¤ ì œëª©: {title}\në‰´ìŠ¤ ë‚´ìš©: {content}\nì–¸ë¡ ì‚¬: {metadata.get('publisher', '')}\në‚ ì§œ: {pub_date}\në¶„ë¥˜: ë‰´ìŠ¤ ê¸°ì‚¬"
                            
                        elif source_type == "ì‡¼í•‘":
                            content = f"{title}. " + re.sub('<[^<]+?>', '', item.get('category3', '')) if item.get('category3') else title
                            metadata = {
                                'title': title,
                                'url': item.get('link', ''),
                                'lprice': item.get('lprice', ''),
                                'hprice': item.get('hprice', ''),
                                'mallname': item.get('mallName', ''),
                                'maker': item.get('maker', ''),
                                'brand': item.get('brand', ''),
                                'collection': source_type
                            }
                            # ê°œì„ ëœ ì „ì²´ í…ìŠ¤íŠ¸ êµ¬ì„±
                            full_text = f"ìƒí’ˆëª…: {title}\nì„¤ëª…: {content}\në¸Œëœë“œ: {metadata.get('brand', '')}\nì œì¡°ì‚¬: {metadata.get('maker', '')}\níŒë§¤ì²˜: {metadata.get('mallname', '')}\nì¹´í…Œê³ ë¦¬: ì‡¼í•‘"
                        
                        # ë¹ˆ í…ìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°
                        if not full_text.strip() or len(full_text.strip()) < 20:
                            continue
                        
                        # ë‰´ìŠ¤ ë°ì´í„° ë””ë²„ê¹… (ì„ì‹œ)
                        if source_type == "ë‰´ìŠ¤" and i < 3:  # ì²˜ìŒ 3ê°œë§Œ ë””ë²„ê¹…
                            st.sidebar.write(f"**ë‰´ìŠ¤ ì €ì¥ ë””ë²„ê¹… {i+1}:**")
                            st.sidebar.write(f"- ì œëª©: {title[:50]}...")
                            st.sidebar.write(f"- ì–¸ë¡ ì‚¬: {metadata.get('publisher', 'N/A')}")
                            st.sidebar.write(f"- í…ìŠ¤íŠ¸ ê¸¸ì´: {len(full_text)}")
                        
                        try:
                            # ì„ë² ë”© ìƒì„±
                            embedding = generate_embedding(full_text)
                            
                            if embedding is None:  # ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ ì‹œ ê±´ë„ˆë›°ê¸°
                                continue
                            
                            # Supabaseì— ë°ì´í„° ì‚½ì…
                            data = {
                                'content': full_text,
                                'embedding': embedding,
                                'metadata': metadata
                            }
                            
                            # ì¤‘ë³µ ì²´í¬ ê°œì„  (ì œëª©ê³¼ URL ê¸°ë°˜)
                            check_url = metadata.get('url', '')
                            
                            try:
                                # URL ê¸°ë°˜ ì¤‘ë³µ ì²´í¬
                                if check_url:
                                    existing = supabase.table('documents').select('id').eq(f"metadata->>url", check_url).execute()
                                    
                                    if not existing.data:  # ì¤‘ë³µì´ ì—†ì„ ê²½ìš°ì—ë§Œ ì‚½ì…
                                        result = supabase.table('documents').insert(data).execute()
                                        saved_count += 1
                                        if source_type == "ë‰´ìŠ¤":
                                            st.sidebar.success(f"ë‰´ìŠ¤ ì €ì¥ ì„±ê³µ: {title[:30]}...")
                                else:
                                    # URLì´ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì €ì¥
                                    result = supabase.table('documents').insert(data).execute()
                                    saved_count += 1
                            
                            except Exception as e:
                                st.warning(f"í•­ëª© {i+1} ì €ì¥ ì¤‘ ìƒì„¸ ì˜¤ë¥˜: {str(e)}")
                                continue
                            
                        except Exception as e:
                            st.warning(f"í•­ëª© {i+1} ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                            continue
                        
                    except Exception as e:
                        st.warning(f"í•­ëª© {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        continue
                
                return items, response_data.get('total', 0), saved_count
            
            else:
                st.error(f"ë„¤ì´ë²„ API HTTP ì˜¤ë¥˜: {response_code}")
                return [], 0, 0
        
        except urllib.error.HTTPError as e:
            st.error(f"ë„¤ì´ë²„ API HTTP ì˜¤ë¥˜: {e.code} - {e.reason}")
            if e.code == 400:
                st.error("ì˜ëª»ëœ ìš”ì²­ì…ë‹ˆë‹¤. ê²€ìƒ‰ì–´ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            elif e.code == 401:
                st.error("ì¸ì¦ ì˜¤ë¥˜ì…ë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            elif e.code == 403:
                st.error("ì ‘ê·¼ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. API ì‚¬ìš© ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            elif e.code == 429:
                st.error("API í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            return [], 0, 0
            
        except urllib.error.URLError as e:
            st.error(f"ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜: {str(e)}")
            return [], 0, 0
            
        except Exception as e:
            st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
            return [], 0, 0
            
    except Exception as e:
        st.error(f"ë„¤ì´ë²„ ê²€ìƒ‰ ì¤‘ ì „ì²´ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return [], 0, 0

def semantic_search(query_text, source_type="ë¸”ë¡œê·¸", limit=10, match_threshold=0.5):
    """ì‹œë§¨í‹± ê²€ìƒ‰ ìˆ˜í–‰ - ê°œì„ ëœ ë²„ì „"""
    try:
        # ì¿¼ë¦¬ ì „ì²˜ë¦¬ë¥¼ ì†ŒìŠ¤ íƒ€ì…ë³„ë¡œ ë‹¤ë¥´ê²Œ
        if source_type == "ë‰´ìŠ¤":
            processed_query = f"ë‰´ìŠ¤ ê²€ìƒ‰: {query_text} ë‰´ìŠ¤ ê¸°ì‚¬ ì–¸ë¡ ì‚¬ ë³´ë„"
        elif source_type == "ì‡¼í•‘":
            processed_query = f"ìƒí’ˆ ê²€ìƒ‰: {query_text} ì‡¼í•‘ ìƒí’ˆ ê°€ê²©"
        else:
            processed_query = f"ë¸”ë¡œê·¸ ê²€ìƒ‰: {query_text} ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…"
        
        # ì¿¼ë¦¬ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±
        query_embedding = generate_embedding(processed_query)
        
        if query_embedding is None:
            st.error("ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return []
        
        # ë””ë²„ê¹…: ì¿¼ë¦¬ ì •ë³´ ì¶œë ¥
        if source_type == "ë‰´ìŠ¤":
            st.sidebar.write(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì¿¼ë¦¬: {processed_query[:50]}...")
            st.sidebar.write(f"ì„ë² ë”© ì°¨ì›: {len(query_embedding)}")
        
        # match_documents í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œ ë²¡í„° ê²€ìƒ‰ - ë” ê´€ëŒ€í•œ ì„¤ì •
        try:
            # ë‰´ìŠ¤ì˜ ê²½ìš° ë” ë‚®ì€ ì„ê³„ê°’ ì‚¬ìš©
            if source_type == "ë‰´ìŠ¤":
                adjusted_threshold = max(0.1, match_threshold - 0.3)
            else:
                adjusted_threshold = max(0.2, match_threshold - 0.2)
            
            response = supabase.rpc(
                'match_documents', 
                {
                    'query_embedding': query_embedding,
                    'match_threshold': adjusted_threshold,
                    'match_count': limit * 5  # í•„í„°ë§ í›„ ì¶©ë¶„í•œ ê²°ê³¼ë¥¼ ìœ„í•´ ë” ë§ì´ ê°€ì ¸ì˜´
                }
            ).execute()
            
            if response.data and len(response.data) > 0:
                # í´ë¼ì´ì–¸íŠ¸ ì¸¡ì—ì„œ ì†ŒìŠ¤ íƒ€ì…ì— ë”°ë¼ í•„í„°ë§
                filtered_results = []
                for item in response.data:
                    # metadata í™•ì¸
                    metadata = item.get('metadata', {})
                    if isinstance(metadata, str):
                        try:
                            metadata = json.loads(metadata)
                        except:
                            metadata = {}
                    
                    item_source_type = metadata.get('collection', '')
                    
                    # ì†ŒìŠ¤ íƒ€ì…ì´ ì¼ì¹˜í•˜ëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
                    if item_source_type == source_type:
                        filtered_results.append(item)
                        # ë‰´ìŠ¤ ë””ë²„ê¹…
                        if source_type == "ë‰´ìŠ¤" and len(filtered_results) <= 3:
                            st.sidebar.write(f"ë‰´ìŠ¤ ë§¤ì¹­ ë°œê²¬: {metadata.get('title', '')[:30]}... (ìœ ì‚¬ë„: {item.get('similarity', 0):.3f})")
                
                # ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ì¬ì •ë ¬
                filtered_results.sort(key=lambda x: x.get('similarity', 0), reverse=True)
                
                # ìµœëŒ€ limit ê°œìˆ˜ë§Œí¼ ê²°ê³¼ ë°˜í™˜
                return filtered_results[:limit]
            else:
                st.info(f"'{query_text}'ì— ëŒ€í•œ {source_type} ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                # ë‰´ìŠ¤ ë””ë²„ê¹…
                if source_type == "ë‰´ìŠ¤":
                    st.sidebar.warning(f"ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ. ì„ê³„ê°’: {adjusted_threshold}")
                return []
                
        except Exception as e:
            st.sidebar.warning(f"ì‹œë§¨í‹± ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
        
    except Exception as e:
        st.error(f"ì‹œë§¨í‹± ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise

def get_system_prompt(source_type):
    """ì†ŒìŠ¤ íƒ€ì…ì— ë”°ë¥¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    if source_type == "ë¸”ë¡œê·¸":
        return """ë‹¹ì‹ ì€ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ë¸”ë¡œê·¸ ê¸€ì€ ê°œì¸ì˜ ê²½í—˜ê³¼ ì˜ê²¬ì„ ë‹´ê³  ìˆìœ¼ë¯€ë¡œ, ì£¼ê´€ì ì¸ ë‚´ìš©ì´ í¬í•¨ë  ìˆ˜ ìˆìŒì„ ì¸ì§€í•˜ì„¸ìš”.
ì—¬ëŸ¬ ë¸”ë¡œê·¸ì˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ê· í˜• ì¡íŒ ì‹œê°ì„ ì œê³µí•˜ë˜, ì •ë³´ì˜ ì¶œì²˜ê°€ ê°œì¸ ë¸”ë¡œê·¸ì„ì„ ëª…ì‹œí•˜ì„¸ìš”.
íŠ¹íˆ ë ˆì‹œí”¼, DIY ë°©ë²•, ì—¬í–‰ ê²½í—˜ ë“± ì‹¤ìš©ì ì¸ ì •ë³´ì— ì§‘ì¤‘í•˜ë˜, ì˜í•™ì  ì¡°ì–¸ì´ë‚˜ ì „ë¬¸ì ì¸ ë‚´ìš©ì€ ì°¸ê³  ì •ë³´ë¡œë§Œ ì•ˆë‚´í•˜ì„¸ìš”."""

    elif source_type == "ë‰´ìŠ¤":
        return """ë‹¹ì‹ ì€ ë„¤ì´ë²„ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ê°ê´€ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì‚¬ì‹¤ê³¼ ì •ë³´ë¥¼ ì „ë‹¬í•  ë•ŒëŠ” í¸í–¥ë˜ì§€ ì•Šê²Œ ì¤‘ë¦½ì ì¸ ì…ì¥ì„ ìœ ì§€í•˜ì„¸ìš”.
ì—¬ëŸ¬ ì–¸ë¡ ì‚¬ì˜ ê¸°ì‚¬ë¥¼ ë¹„êµí•˜ì—¬ ë‹¤ì–‘í•œ ê´€ì ì„ ì œì‹œí•˜ê³ , ì •ë³´ì˜ ì¶œì²˜ì™€ ë°œí–‰ ë‚ ì§œë¥¼ ëª…í™•íˆ í•˜ì„¸ìš”.
íŠ¹íˆ ì‹œì‚¬ ë¬¸ì œ, ìµœì‹  ì´ìŠˆ, ì‚¬íšŒ í˜„ìƒì— ëŒ€í•´ ì„¤ëª…í•  ë•ŒëŠ” ë‹¤ì–‘í•œ ì˜ê²¬ì´ ìˆì„ ìˆ˜ ìˆìŒì„ ì¸ì§€í•˜ì„¸ìš”."""

    elif source_type == "ì‡¼í•‘":
        return """ë‹¹ì‹ ì€ ë„¤ì´ë²„ ì‡¼í•‘ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ìƒí’ˆ ì •ë³´, ê°€ê²©, ê¸°ëŠ¥, íŠ¹ì§• ë“±ì„ ê°ê´€ì ìœ¼ë¡œ ì„¤ëª…í•˜ê³  ë¹„êµí•˜ì„¸ìš”.
ë‹¤ì–‘í•œ ìƒí’ˆ ì˜µì…˜ê³¼ ê°€ê²©ëŒ€ë¥¼ ì•ˆë‚´í•˜ë˜, íŠ¹ì • ë¸Œëœë“œë‚˜ ì œí’ˆì„ ì§€ë‚˜ì¹˜ê²Œ í™ë³´í•˜ì§€ ë§ˆì„¸ìš”.
ì‚¬ìš©ìì˜ ìš”êµ¬ì— ë§ëŠ” ìƒí’ˆ ì¶”ì²œì´ë‚˜ êµ¬ë§¤ íŒì„ ì œê³µí•  ë•ŒëŠ” ì‹¤ìš©ì ì¸ ê´€ì ì—ì„œ ì ‘ê·¼í•˜ì„¸ìš”."""

    else:
        return """ë‹¹ì‹ ì€ ë„¤ì´ë²„ ê²€ìƒ‰ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ëŠ” ìµœì ì˜ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ê°€í•˜ì§€ ë§ê³  ì •í™•í•œ ì‚¬ì‹¤ë§Œ ì „ë‹¬í•˜ì„¸ìš”."""

def get_user_prompt(query, context_text, source_type):
    """ì†ŒìŠ¤ íƒ€ì…ì— ë”°ë¥¸ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    if source_type == "ë¸”ë¡œê·¸":
        return f"""ë‹¤ìŒì€ ë„¤ì´ë²„ ë¸”ë¡œê·¸ì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„°ì…ë‹ˆë‹¤:

{context_text}

ìœ„ ë¸”ë¡œê·¸ ê¸€ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ìƒì„¸íˆ ë‹µë³€í•´ì£¼ì„¸ìš”: 
"{query}"

ë‹µë³€ ì‘ì„± ê·œì¹™:
1. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
2. ë¸”ë¡œê·¸ ê¸€ì€ ê°œì¸ì˜ ê²½í—˜ê³¼ ì˜ê²¬ì„ ë‹´ê³  ìˆìœ¼ë¯€ë¡œ, ì •ë³´ì˜ ì£¼ê´€ì„±ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”.
3. ì—¬ëŸ¬ ë¸”ë¡œê·¸ì˜ ê³µí†µëœ ë‚´ìš©ì— ì¤‘ì ì„ ë‘ê³ , ê°œì¸ì  ê²½í—˜ì´ë‚˜ íŒì€ "ë¸”ë¡œê±°ì˜ ê²½í—˜ì— ë”°ë¥´ë©´..."ê³¼ ê°™ì´ ë§¥ë½ì„ ì œê³µí•´ì£¼ì„¸ìš”.
4. ë¸”ë¡œê·¸ ê¸€ë“¤ ê°„ì— ìƒì¶©ë˜ëŠ” ì •ë³´ê°€ ìˆë‹¤ë©´ "ì¼ë¶€ ë¸”ë¡œê±°ëŠ” Aë¥¼ ì¶”ì²œí•˜ëŠ” ë°˜ë©´, ë‹¤ë¥¸ ë¸”ë¡œê±°ëŠ” Bë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤"ì™€ ê°™ì´ ë‹¤ì–‘í•œ ì˜ê²¬ì„ ì œì‹œí•´ì£¼ì„¸ìš”.
5. ë ˆì‹œí”¼, DIY ë°©ë²•, ì—¬í–‰ ê²½í—˜ ë“± ì‹¤ìš©ì ì¸ ì •ë³´ì— ì§‘ì¤‘í•´ì£¼ì„¸ìš”.
6. ì¶œì²˜ë¥¼ ëª…ì‹œí•  ë•ŒëŠ” "ë¬¸ì„œ 2ì˜ ë¸”ë¡œê±°ì— ë”°ë¥´ë©´..."ê³¼ ê°™ì´ í‘œí˜„í•´ì£¼ì„¸ìš”.
7. ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ê³ , ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ê±°ë‚˜ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”."""

    elif source_type == "ë‰´ìŠ¤":
        return f"""ë‹¤ìŒì€ ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ìˆ˜ì§‘í•œ, ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ì˜ ê¸°ì‚¬ì…ë‹ˆë‹¤:

{context_text}

ìœ„ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ìƒì„¸íˆ ë‹µë³€í•´ì£¼ì„¸ìš”: 
"{query}"

ë‹µë³€ ì‘ì„± ê·œì¹™:
1. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
2. ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì‚¬ì‹¤ê³¼ ì •ë³´ë¥¼ ì „ë‹¬í•  ë•ŒëŠ” í¸í–¥ë˜ì§€ ì•Šê²Œ ì¤‘ë¦½ì ì¸ ì…ì¥ì„ ìœ ì§€í•˜ì„¸ìš”.
3. ê¸°ì‚¬ì˜ ë°œí–‰ ë‚ ì§œë¥¼ ê³ ë ¤í•˜ì—¬ ì •ë³´ì˜ ì‹œì˜ì„±ì„ ëª…ì‹œí•˜ì„¸ìš”. (ì˜ˆ: "2023ë…„ 5ì›” ë³´ë„ì— ë”°ë¥´ë©´...")
4. ì—¬ëŸ¬ ì–¸ë¡ ì‚¬ì˜ ê¸°ì‚¬ë¥¼ ì¸ìš©í•  ë•ŒëŠ” "ë¬¸ì„œ 1ì˜ OOì¼ë³´ì— ë”°ë¥´ë©´..."ì™€ ê°™ì´ ì¶œì²˜ë¥¼ ëª…í™•íˆ í•˜ì„¸ìš”.
5. ê¸°ì‚¬ë“¤ ê°„ì— ìƒì¶©ë˜ëŠ” ì •ë³´ê°€ ìˆë‹¤ë©´ ì´ë¥¼ ì–¸ê¸‰í•˜ê³  ê° ê´€ì ì„ ê³µì •í•˜ê²Œ ì œì‹œí•˜ì„¸ìš”.
6. ì œê³µëœ ê¸°ì‚¬ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ê³ , ê¸°ì‚¬ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ê±°ë‚˜ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”."""

    elif source_type == "ì‡¼í•‘":
        return f"""ë‹¤ìŒì€ ë„¤ì´ë²„ ì‡¼í•‘ì—ì„œ ìˆ˜ì§‘í•œ ìƒí’ˆ ì •ë³´ì…ë‹ˆë‹¤:

{context_text}

ìœ„ ì‡¼í•‘ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ìƒì„¸íˆ ë‹µë³€í•´ì£¼ì„¸ìš”: 
"{query}"

ë‹µë³€ ì‘ì„± ê·œì¹™:
1. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
2. ìƒí’ˆì˜ ê°€ê²©, ê¸°ëŠ¥, íŠ¹ì§• ë“±ì„ ê°ê´€ì ìœ¼ë¡œ ì„¤ëª…í•˜ê³  ë¹„êµí•´ì£¼ì„¸ìš”.
3. ê°€ê²©ì€ ë²”ìœ„ë¡œ í‘œí˜„í•˜ê³  ì •í™•í•œ ê°€ê²©ì´ ìˆë‹¤ë©´ ì–¸ê¸‰í•´ì£¼ì„¸ìš”. (ì˜ˆ: "ì´ ì œí’ˆì€ 30,000ì›ì—ì„œ 50,000ì› ì‚¬ì´ì˜ ê°€ê²©ëŒ€ë¥¼ í˜•ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤")
4. ë‹¤ì–‘í•œ ë¸Œëœë“œì™€ ì œí’ˆì„ ê· í˜• ìˆê²Œ ì†Œê°œí•˜ê³ , íŠ¹ì • ìƒí’ˆì„ ì§€ë‚˜ì¹˜ê²Œ í™ë³´í•˜ì§€ ë§ˆì„¸ìš”.
5. ìƒí’ˆì˜ íŠ¹ì§•ì„ ë¹„êµí•  ë•ŒëŠ” "A ì œí’ˆì€ X ê¸°ëŠ¥ì´ ìˆì§€ë§Œ, B ì œí’ˆì€ Y ê¸°ëŠ¥ì´ ê°•ì¡°ë©ë‹ˆë‹¤"ì™€ ê°™ì´ ê°ê´€ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
6. ì œê³µëœ ìƒí’ˆ ì •ë³´ë§Œ ì‚¬ìš©í•˜ê³ , ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ê±°ë‚˜ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”."""

    else:
        return f"""ë‹¤ìŒì€ ë„¤ì´ë²„ ê²€ìƒ‰ì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„°ì…ë‹ˆë‹¤:

{context_text}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ìƒì„¸íˆ ë‹µë³€í•´ì£¼ì„¸ìš”: 
"{query}"

ë‹µë³€ ì‘ì„± ê·œì¹™:
1. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
2. ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
3. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ê±°ë‚˜ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”.
4. ì—¬ëŸ¬ ë¬¸ì„œ ê°„ì— ìƒì¶©ë˜ëŠ” ì •ë³´ê°€ ìˆë‹¤ë©´ ì´ë¥¼ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
5. ë‹µë³€ì— ì ì ˆí•œ ì •ë³´ê°€ ë¶€ì¡±í•˜ë‹¤ë©´ ì†”ì§í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”.
6. ë‹µë³€ì€ ë…¼ë¦¬ì ì¸ êµ¬ì¡°ë¡œ ì •ë¦¬í•˜ì—¬ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
7. í•„ìš”í•œ ê²½ìš° ì •ë³´ì˜ ì¶œì²˜ë¥¼ ì–¸ê¸‰í•´ì£¼ì„¸ìš”(ì˜ˆ: "ë¬¸ì„œ 2ì— ë”°ë¥´ë©´...")."""

def generate_answer_with_gpt(query, search_results, source_type):
    """GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ì— ê¸°ë°˜í•œ ë‹µë³€ ìƒì„±"""
    try:
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
        if not search_results:
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì…ë ¥í•˜ì‹  '{query}'ì— ëŒ€í•œ {source_type} ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë‚˜ ë‹¤ë¥¸ ì†ŒìŠ¤ íƒ€ì…ìœ¼ë¡œ ì‹œë„í•´ë³´ì„¸ìš”."
            
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬
        contexts = []
        for i, result in enumerate(search_results[:5]):  # ìƒìœ„ 5ê°œ ê²°ê³¼ë§Œ ì‚¬ìš©
            content = result['content']
            
            # metadata í™•ì¸ (JSON ë¬¸ìì—´ì¼ ê²½ìš° íŒŒì‹±)
            metadata = result.get('metadata', {})
            if isinstance(metadata, str):
                try:
                    metadata = json.loads(metadata)
                except:
                    metadata = {}
                    
            title = metadata.get('title', 'ì œëª© ì—†ìŒ')
            date = metadata.get('date', '')  # ë‚ ì§œ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            
            # ë‚ ì§œ ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨
            date_info = f" (ì‘ì„±ì¼: {date})" if date else ""
            
            # ì†ŒìŠ¤ íƒ€ì…ì— ë§ëŠ” ì¶”ê°€ ì •ë³´
            if source_type == "ë¸”ë¡œê·¸" and 'bloggername' in metadata:
                source_info = f" - ë¸”ë¡œê±°: {metadata['bloggername']}"
            elif source_type == "ë‰´ìŠ¤" and 'publisher' in metadata:
                source_info = f" - ì¶œì²˜: {metadata['publisher']}"
            elif source_type == "ì‡¼í•‘" and 'mallname' in metadata:
                price_info = f", ê°€ê²©: {metadata.get('lprice', 'ì •ë³´ ì—†ìŒ')}ì›" if 'lprice' in metadata else ""
                source_info = f" - íŒë§¤ì²˜: {metadata['mallname']}{price_info}"
            else:
                source_info = ""
            
            # ìœ ì‚¬ë„ ì ìˆ˜ ì¶”ê°€
            similarity = result.get('similarity', 0) * 100
            similarity_info = f" (ìœ ì‚¬ë„: {similarity:.1f}%)"
            
            # ì¶œì²˜ íƒ€ì…ê³¼ í•¨ê»˜ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            contexts.append(f"ë¬¸ì„œ {i+1} - [{source_type}] {title}{date_info}{source_info}{similarity_info}:\n{content}\n")
        
        context_text = "\n".join(contexts)
        
        # ì†ŒìŠ¤ íƒ€ì…ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = get_system_prompt(source_type)
        user_prompt = get_user_prompt(query, context_text, source_type)

        # GPT-4o-minië¡œ ë‹µë³€ ìƒì„±
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,  # ì¼ê´€ì„± ìˆëŠ” ë‹µë³€ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„ ì„¤ì •
            max_tokens=1000    # ì¶©ë¶„í•œ ë‹µë³€ ê¸¸ì´
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        st.error(f"GPT ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# ë©”ì¸ UI
st.title("ğŸ›ï¸ ìŠ¤ë§ˆíŠ¸ ì‡¼í•‘ íŒŒì¸ë”: ë„¤ì´ë²„ ê²€ìƒ‰ & AI ë‹µë³€")
st.write("ë˜‘ë˜‘í•œ ì‡¼í•‘ì„ ìœ„í•œ ë§ì¶¤í˜• ê²€ìƒ‰! ë„¤ì´ë²„ ì‡¼í•‘, ë¸”ë¡œê·¸, ë‰´ìŠ¤ ì •ë³´ë¥¼ AIê°€ ìš”ì•½í•˜ê³  ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤.")

# ê²€ìƒ‰ ëª¨ë“œ ì„ íƒ (ì‚¬ì´ë“œë°”)
search_mode = st.sidebar.radio(
    "ê²€ìƒ‰ ëª¨ë“œ ì„ íƒ",
    options=["ì‹œë§¨í‹± ê²€ìƒ‰ (ì €ì¥ëœ ë°ì´í„°)", "ìƒˆ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥"],
    index=0
)

# --- ê²€ìƒ‰ ì†ŒìŠ¤ ë° ì§ˆë¬¸ ì…ë ¥ ë¡œì§ ---
source_options = ["ì‡¼í•‘", "ë¸”ë¡œê·¸", "ë‰´ìŠ¤"]  # ê²€ìƒ‰ ì†ŒìŠ¤ ìˆœì„œ: ì‡¼í•‘ â†’ ë¸”ë¡œê·¸ â†’ ë‰´ìŠ¤

vape_questions = [
    "ê°€ì„±ë¹„ ì¢‹ì€ ì „ìë‹´ë°° ì¶”ì²œí•´ ì£¼ì„¸ìš”.",
    "ì „ìë‹´ë°° ì•¡ìƒ ì¶”ì²œí•´ì£¼ì„¸ìš”.",
    "ì…í˜¸í¡ê³¼ íí˜¸í¡ ì „ìë‹´ë°° ì°¨ì´ì ì´ ë­ì˜ˆìš”?"
]

default_queries_map = {
    "ì‡¼í•‘": vape_questions[0],  # ì‡¼í•‘ íƒ­ ê¸°ë³¸ ì§ˆë¬¸
    "ë¸”ë¡œê·¸": "ì „ìë‹´ë°° ì´ˆë³´ìê°€ ì•Œì•„ì•¼ í•  ê¿€íŒì´ ë­ê°€ ìˆë‚˜ìš”?",
    "ë‰´ìŠ¤": "ì „ìë‹´ë°° ê´€ë ¨ ìµœì‹  ê·œì œë‚˜ ì´ìŠˆê°€ ìˆë‚˜ìš”?"
}


# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì•± ë¡œë“œ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ë„ë¡)
if "query_input" not in st.session_state:
    # ì•± ì²˜ìŒ ë¡œë“œ ì‹œ ê¸°ë³¸ ì†ŒìŠ¤("ì‡¼í•‘")ì˜ ê¸°ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ì´ˆê¸°í™”
    st.session_state.query_input = default_queries_map[source_options[0]]
if "current_source_type" not in st.session_state:
    st.session_state.current_source_type = source_options[0] # ì´ˆê¸° ì†ŒìŠ¤ íƒ€ì…ì€ "ì‡¼í•‘"

# ê²€ìƒ‰ ì†ŒìŠ¤ ë³€ê²½ ì‹œ í˜¸ì¶œë  ì½œë°± í•¨ìˆ˜
def source_type_on_change():
    # st.session_state.source_type_radio_key ëŠ” radio ë²„íŠ¼ì˜ í˜„ì¬ ì„ íƒëœ ê°’
    new_source_type = st.session_state.source_type_radio_key 
    st.session_state.current_source_type = new_source_type
    st.session_state.query_input = default_queries_map[new_source_type]
    # ì½œë°± ë‚´ì—ì„œ st.rerun()ì€ Streamlitì´ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ ëª…ì‹œì ìœ¼ë¡œ í˜¸ì¶œí•  í•„ìš” ì—†ìŒ

# ê²€ìƒ‰ ì†ŒìŠ¤ ì„ íƒ ë¼ë””ì˜¤ ë²„íŠ¼
selected_source_from_radio = st.radio(
    "ê²€ìƒ‰ ì†ŒìŠ¤ ì„ íƒ",
    options=source_options,
    index=source_options.index(st.session_state.current_source_type), # í˜„ì¬ ì„¸ì…˜ ìƒíƒœì˜ ì¸ë±ìŠ¤ ì‚¬ìš©
    horizontal=True,
    key="source_type_radio_key", # on_change ì½œë°±ì—ì„œ ì´ í‚¤ë¥¼ í†µí•´ ê°’ì„ ì°¸ì¡°
    on_change=source_type_on_change
)
# selected_source_from_radioëŠ” í˜„ì¬ UIì˜ ê°’. ì‹¤ì œ ê´€ë¦¬ë˜ëŠ” ìƒíƒœëŠ” st.session_state.current_source_type
active_source_type = st.session_state.current_source_type

# ê²€ìƒ‰ ì…ë ¥ í•„ë“œ ë„ì›€ë§ í…ìŠ¤íŠ¸
help_texts = {
    "ì‡¼í•‘": "ì „ìë‹´ë°° ì¶”ì²œ ì§ˆë¬¸ì„ í´ë¦­í•˜ê±°ë‚˜ ì§ì ‘ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: ê°€ì„±ë¹„ ì „ìë‹´ë°°)",
    "ë¸”ë¡œê·¸": "ë¸”ë¡œê·¸ ê´€ë ¨ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: ì „ìë‹´ë°° ì•¡ìƒ ì¶”ì²œ, ì…í˜¸í¡ íŒ)",
    "ë‰´ìŠ¤": "ì „ìë‹´ë°° ê´€ë ¨ ë‰´ìŠ¤ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: ì „ìë‹´ë°° ê·œì œ, ê±´ê°• ì´ìŠˆ)"
}
current_help_text = help_texts[active_source_type]

# ê²€ìƒ‰ì–´ ì…ë ¥ì°½
user_typed_query = st.text_input(
    "ì§ˆë¬¸ ì…ë ¥",
    value=st.session_state.query_input, # ì„¸ì…˜ ìƒíƒœì˜ ê°’ì„ í‘œì‹œ
    help=current_help_text,
    key="query_text_input_widget" # ìœ„ì ¯ ìì²´ì˜ í‚¤
)
# ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•œ ê²½ìš°, ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
if user_typed_query != st.session_state.query_input:
    st.session_state.query_input = user_typed_query
    # ì´ ì—…ë°ì´íŠ¸ëŠ” ë‹¤ìŒ rerun ì‹œ ë°˜ì˜ë¨ (íƒ€ì´í•‘ ì¤‘ ê³„ì† rerun ë°©ì§€)

# "ì‡¼í•‘" íƒ­ì¼ ë•Œ ì „ìë‹´ë°° ì¶”ì²œ ì§ˆë¬¸ ë²„íŠ¼ í‘œì‹œ
if active_source_type == "ì‡¼í•‘":
    st.markdown("ğŸ‘‡ **ì „ìë‹´ë°° ê´€ë ¨ ì¶”ì²œ ì§ˆë¬¸ì„ ì„ íƒí•´ë³´ì„¸ìš”!**")
    cols = st.columns(len(vape_questions))
    for i, q_text in enumerate(vape_questions):
        if cols[i].button(q_text, key=f"vape_q_btn_{i}"):
            st.session_state.query_input = q_text  # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.rerun()  # ë²„íŠ¼ í´ë¦­ ì‹œ í…ìŠ¤íŠ¸ ì…ë ¥ í•„ë“œë¥¼ ì¦‰ì‹œ ì—…ë°ì´íŠ¸í•˜ê³  UIë¥¼ ìƒˆë¡œê³ ì¹¨

# ìµœì¢…ì ìœ¼ë¡œ ì‚¬ìš©í•  ì¿¼ë¦¬ëŠ” st.session_state.query_input
query_to_use_in_search = st.session_state.query_input

# ì›ë³¸ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ ì˜µì…˜
show_raw_results = st.sidebar.checkbox("ì›ë³¸ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ", value=True)

# ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ë° ìœ ì‚¬ë„ ì„¤ì •
if search_mode == "ì‹œë§¨í‹± ê²€ìƒ‰ (ì €ì¥ëœ ë°ì´í„°)":
    col1, col2 = st.sidebar.columns(2)
    with col1:
        result_count = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", min_value=3, max_value=20, value=10)
    with col2:
        similarity_threshold = st.slider("ìœ ì‚¬ë„ ì„ê³„ê°’", min_value=0.0, max_value=1.0, value=0.4, step=0.05)
else:
    result_count = st.sidebar.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", min_value=5, max_value=50, value=20)

# ê²€ìƒ‰ ë²„íŠ¼
search_button_text = "ì‹œë§¨í‹± ê²€ìƒ‰" if search_mode == "ì‹œë§¨í‹± ê²€ìƒ‰ (ì €ì¥ëœ ë°ì´í„°)" else "ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥"
if st.button(f"{active_source_type}ì—ì„œ {search_button_text}", key="search_button"):
    if query_to_use_in_search:
        if search_mode == "ì‹œë§¨í‹± ê²€ìƒ‰ (ì €ì¥ëœ ë°ì´í„°)":
            with st.spinner(f"{active_source_type} ì‹œë§¨í‹± ê²€ìƒ‰ ì¤‘..."):
                try:
                    results = semantic_search(query_to_use_in_search, source_type=active_source_type, limit=result_count, match_threshold=similarity_threshold)
                    
                    if results:
                        st.success(f"{len(results)}ê°œì˜ {active_source_type} ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                        with st.spinner("AI ì—ì´ì „íŠ¸ ë‹µë³€ ìƒì„± ì¤‘..."):
                            gpt_answer = generate_answer_with_gpt(query_to_use_in_search, results, active_source_type)
                            st.markdown(f"## AI ë‹µë³€ ({active_source_type} ë°ì´í„° ê¸°ë°˜)")
                            st.markdown(gpt_answer)
                            st.markdown("---")
                        
                        if show_raw_results:
                            st.markdown(f"## {active_source_type} ê²€ìƒ‰ ê²°ê³¼ ì›ë³¸")
                            for i, result in enumerate(results):
                                similarity = result['similarity'] * 100
                                metadata = result.get('metadata', {})
                                if isinstance(metadata, str):
                                    try: metadata = json.loads(metadata)
                                    except: metadata = {}
                                title = metadata.get('title', 'ì œëª© ì—†ìŒ')
                                url = metadata.get('url', None)
                                with st.expander(f"{i+1}. {title} (ìœ ì‚¬ë„: {similarity:.2f}%)"):
                                    st.write(f"**ë‚´ìš©:** {result['content']}")
                                    meta_col1, meta_col2 = st.columns(2)
                                    with meta_col1:
                                        if active_source_type == "ë¸”ë¡œê·¸" and 'bloggername' in metadata: st.write(f"**ë¸”ë¡œê±°:** {metadata['bloggername']}")
                                        elif active_source_type == "ë‰´ìŠ¤" and 'publisher' in metadata: st.write(f"**ì–¸ë¡ ì‚¬:** {metadata['publisher']}")
                                        elif active_source_type == "ì‡¼í•‘" and 'maker' in metadata: st.write(f"**ì œì¡°ì‚¬:** {metadata['maker']}")
                                        elif active_source_type == "ì‡¼í•‘" and 'brand' in metadata: st.write(f"**ë¸Œëœë“œ:** {metadata['brand']}")
                                        if 'date' in metadata: st.write(f"**ë‚ ì§œ:** {metadata['date']}")
                                    with meta_col2:
                                        if url: st.markdown(f"**ë§í¬:** [ì›ë³¸ ë³´ê¸°]({url})")
                                        if active_source_type == "ì‡¼í•‘":
                                            if 'lprice' in metadata: st.write(f"**ìµœì €ê°€:** {metadata['lprice']}ì›")
                                            if 'mallname' in metadata: st.write(f"**íŒë§¤ì²˜:** {metadata['mallname']}")
                    else:
                        st.warning(f"{active_source_type}ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê±°ë‚˜ ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
                        st.info("ğŸ’¡ íŒ: ìœ ì‚¬ë„ ì„ê³„ê°’ì„ ë” ë‚®ì¶”ê±°ë‚˜, ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
                except Exception as e:
                    st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        else: # ìƒˆ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥ ëª¨ë“œ
            with st.spinner(f"ë„¤ì´ë²„ {active_source_type} API ê²€ìƒ‰ ë° ë°ì´í„° ì €ì¥ ì¤‘..."):
                try:
                    items, total_count, saved_count = search_naver_api(query_to_use_in_search, active_source_type, result_count)
                    
                    if items:
                        st.success(f"ë„¤ì´ë²„ {active_source_type}ì—ì„œ ì´ {total_count}ê°œ ì¤‘ {len(items)}ê°œì˜ ê²°ê³¼ë¥¼ ì°¾ì•˜ê³ , {saved_count}ê°œë¥¼ ìƒˆë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
                        with st.spinner("ì €ì¥ëœ ë°ì´í„°ë¡œ ì‹œë§¨í‹± ê²€ìƒ‰ ì¤‘..."):
                            time.sleep(5)
                            results = semantic_search(query_to_use_in_search, source_type=active_source_type, limit=result_count, match_threshold=0.3)
                            if results:
                                with st.spinner("AI ì—ì´ì „íŠ¸ ë‹µë³€ ìƒì„± ì¤‘..."):
                                    gpt_answer = generate_answer_with_gpt(query_to_use_in_search, results, active_source_type)
                                    st.markdown(f"## AI ë‹µë³€ ({active_source_type} ë°ì´í„° ê¸°ë°˜)")
                                    st.markdown(gpt_answer)
                                    st.markdown("---")
                            else:
                                st.warning("ë°ì´í„°ëŠ” ì €ì¥ë˜ì—ˆì§€ë§Œ ì‹œë§¨í‹± ê²€ìƒ‰ì—ì„œ ê´€ë ¨ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”.")
                                st.info("ğŸ’¡ ìƒˆë¡œ ì €ì¥ëœ ë°ì´í„°ì˜ ì„ë² ë”© ì²˜ë¦¬ê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ëª‡ ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        
                        if show_raw_results:
                            st.markdown(f"## ë„¤ì´ë²„ {active_source_type} ê²€ìƒ‰ ê²°ê³¼")
                            df_data = []
                            for i, item in enumerate(items):
                                try:
                                    title = re.sub('<[^<]+?>', '', item.get('title', '')) if item.get('title') else 'ì œëª© ì—†ìŒ'
                                    if active_source_type == "ë¸”ë¡œê·¸":
                                        description = re.sub('<[^<]+?>', '', item.get('description', '')) if item.get('description') else ''
                                        df_data.append({'ì œëª©': title, 'ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°': description[:100] + "..." if len(description) > 100 else description, 'ë¸”ë¡œê±°': item.get('bloggername', ''), 'ë‚ ì§œ': item.get('postdate', ''), 'ë§í¬': item.get('link', '')})
                                    elif active_source_type == "ë‰´ìŠ¤":
                                        description = re.sub('<[^<]+?>', '', item.get('description', '')) if item.get('description') else ''
                                        df_data.append({'ì œëª©': title, 'ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°': description[:100] + "..." if len(description) > 100 else description, 'ì–¸ë¡ ì‚¬': item.get('originallink', '').replace('https://', '').replace('http://', '').split('/')[0] if item.get('originallink') else '', 'ë‚ ì§œ': item.get('pubDate', ''), 'ë§í¬': item.get('link', '')})
                                    elif active_source_type == "ì‡¼í•‘":
                                        price_display = f"{item.get('lprice', '')}ì›" if item.get('lprice') else 'ê°€ê²© ì •ë³´ ì—†ìŒ'
                                        df_data.append({'ì œí’ˆëª…': title, 'ê°€ê²©': price_display, 'íŒë§¤ì²˜': item.get('mallName', ''), 'ì œì¡°ì‚¬': item.get('maker', ''), 'ë§í¬': item.get('link', '')})
                                except Exception as e:
                                    st.warning(f"í•­ëª© {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                                    continue
                            if df_data:
                                df = pd.DataFrame(df_data)
                                st.dataframe(df, use_container_width=True)
                                for i, item in enumerate(items):
                                    try:
                                        title = re.sub('<[^<]+?>', '', item.get('title', '')) if item.get('title') else 'ì œëª© ì—†ìŒ'
                                        with st.expander(f"{i+1}. {title}"):
                                            if active_source_type in ["ë¸”ë¡œê·¸", "ë‰´ìŠ¤"]:
                                                description = re.sub('<[^<]+?>', '', item.get('description', '')) if item.get('description') else ''
                                                if description: st.write(f"**ë‚´ìš©:** {description}")
                                            meta_col1, meta_col2 = st.columns(2)
                                            with meta_col1:
                                                if active_source_type == "ë¸”ë¡œê·¸":
                                                    if item.get('bloggername'): st.write(f"**ë¸”ë¡œê±°:** {item.get('bloggername')}")
                                                    if item.get('postdate'): st.write(f"**ë‚ ì§œ:** {item.get('postdate')}")
                                                elif active_source_type == "ë‰´ìŠ¤":
                                                    if item.get('originallink'): publisher = item.get('originallink', '').replace('https://', '').replace('http://', '').split('/')[0]; st.write(f"**ì–¸ë¡ ì‚¬:** {publisher}")
                                                    if item.get('pubDate'): st.write(f"**ë‚ ì§œ:** {item.get('pubDate')}")
                                                elif active_source_type == "ì‡¼í•‘":
                                                    if item.get('maker'): st.write(f"**ì œì¡°ì‚¬:** {item.get('maker')}")
                                                    if item.get('brand'): st.write(f"**ë¸Œëœë“œ:** {item.get('brand')}")
                                            with meta_col2:
                                                if item.get('link'): st.markdown(f"**ë§í¬:** [ì›ë³¸ ë³´ê¸°]({item.get('link')})")
                                                if active_source_type == "ì‡¼í•‘":
                                                    if item.get('lprice'): st.write(f"**ìµœì €ê°€:** {item.get('lprice')}ì›")
                                                    if item.get('mallName'): st.write(f"**íŒë§¤ì²˜:** {item.get('mallName')}")
                                    except Exception as e:
                                        st.warning(f"í•­ëª© {i+1} í‘œì‹œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                                        continue
                            else: st.warning("í‘œì‹œí•  ìˆ˜ ìˆëŠ” ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning(f"ë„¤ì´ë²„ {active_source_type}ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë‚˜ ë‹¤ë¥¸ ì†ŒìŠ¤ íƒ€ì…ìœ¼ë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
                except Exception as e:
                    st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    import traceback
                    st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    else:
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")

# ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ
st.sidebar.title("ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ")
try:
    result = supabase.table('documents').select('id', count='exact').execute()
    doc_count = result.count if hasattr(result, 'count') else len(result.data)
    st.sidebar.info(f"ì €ì¥ëœ ì´ ë¬¸ì„œ ìˆ˜: {doc_count}ê°œ")
    try:
        collections = {}
        collection_query = supabase.table('documents').select('metadata').execute()
        for item in collection_query.data:
            metadata = item.get('metadata', {})
            if isinstance(metadata, str):
                try: metadata = json.loads(metadata)
                except: continue
            collection = metadata.get('collection', 'ê¸°íƒ€')
            if collection in collections: collections[collection] += 1
            else: collections[collection] = 1
        for collection, count in collections.items():
            st.sidebar.info(f"{collection} ë¬¸ì„œ ìˆ˜: {count}ê°œ")
    except Exception as e:
        st.sidebar.warning(f"ì†ŒìŠ¤ë³„ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
except Exception as e:
    st.sidebar.error(f"ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

# ë‰´ìŠ¤ ë°ì´í„° ìƒ˜í”Œ í™•ì¸ ë²„íŠ¼ ì¶”ê°€
if st.sidebar.button("ë‰´ìŠ¤ ë°ì´í„° ìƒ˜í”Œ í™•ì¸"):
    try:
        with st.spinner("ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì¤‘..."):
            news_sample = supabase.table('documents').select('*').eq('metadata->>collection', 'ë‰´ìŠ¤').limit(5).execute()
            if news_sample.data:
                st.sidebar.write("### ì €ì¥ëœ ë‰´ìŠ¤ ë°ì´í„° ìƒ˜í”Œ")
                for i, item in enumerate(news_sample.data):
                    st.sidebar.write(f"**ìƒ˜í”Œ {i+1}:**")
                    st.sidebar.write(f"ë‚´ìš©: {item['content'][:100]}...")
                    metadata = item.get('metadata', {})
                    if isinstance(metadata, str):
                        try: metadata = json.loads(metadata)
                        except: metadata = {}
                    st.sidebar.write(f"ë©”íƒ€ë°ì´í„°: {metadata}")
                    st.sidebar.write("---")
            else:
                st.sidebar.warning("ì €ì¥ëœ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.sidebar.error(f"ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

# ì‚¬ìš© ì•ˆë‚´
st.sidebar.title("ì‚¬ìš© ì•ˆë‚´")
st.sidebar.info(f"""
**ê²€ìƒ‰ ëª¨ë“œ:**
1. **ì‹œë§¨í‹± ê²€ìƒ‰ (ì €ì¥ëœ ë°ì´í„°)**: ì´ë¯¸ ì €ì¥ëœ ë°ì´í„°ë¥¼ ì˜ë¯¸ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
2. **ìƒˆ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥**: ë„¤ì´ë²„ APIì—ì„œ ìƒˆ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ì €ì¥í•˜ê³  ê²€ìƒ‰í•©ë‹ˆë‹¤.

**ê²€ìƒ‰ ì†ŒìŠ¤ ì„ íƒ:** ì‡¼í•‘, ë¸”ë¡œê·¸, ë‰´ìŠ¤ ì¤‘ì—ì„œ ê²€ìƒ‰í•  ì†ŒìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”. ì‡¼í•‘ì´ ê¸°ë³¸ì…ë‹ˆë‹¤.

**ìœ ì‚¬ë„ ì„ê³„ê°’:** ì‹œë§¨í‹± ê²€ìƒ‰ì—ì„œ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œ ê²°ê³¼ë¥¼ í¬í•¨í• ì§€ ê²°ì •í•©ë‹ˆë‹¤. 
- ë†’ìŒ (0.7~1.0): ë§¤ìš° ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë§Œ í‘œì‹œ
- ì¤‘ê°„ (0.4~0.6): ê· í˜•ì¡íŒ ê´€ë ¨ì„± (ê¶Œì¥)
- ë‚®ìŒ (0.1~0.3): ë” ë§ì€ ê²°ê³¼ë¥¼ í¬í•¨í•˜ì§€ë§Œ ê´€ë ¨ì„±ì´ ë‚®ì„ ìˆ˜ ìˆìŒ

ğŸ’¡ **ê°œì„  ì‚¬í•­:**
- ì‡¼í•‘ ì •ë³´ ê²€ìƒ‰ì— ìµœì í™”
- ì‚¼ì„± ë…¸íŠ¸ë¶ ê´€ë ¨ ì¶”ì²œ ì§ˆë¬¸ ì œê³µ (ì‡¼í•‘ íƒ­)
- ë‰´ìŠ¤ ë°ì´í„° ì €ì¥ í˜•ì‹ ê°œì„ 
- ë‰´ìŠ¤ ì „ìš© ë‚®ì€ ìœ ì‚¬ë„ ì„ê³„ê°’ ì ìš©
- ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ì¶œ ë¡œì§ ê°œì„ 
- ë‰´ìŠ¤ ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™”

ğŸ’¡ íŒ: ê° ì†ŒìŠ¤ íƒ€ì…ì— ì í•©í•œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:
- ì‡¼í•‘: ìƒí’ˆ ì •ë³´, ê°€ê²© ë¹„êµ, êµ¬ë§¤ íŒ ë“± (ì˜ˆ: ì‚¼ì„± ë…¸íŠ¸ë¶ ì¶”ì²œ)
- ë¸”ë¡œê·¸: ë ˆì‹œí”¼, ì—¬í–‰ ê²½í—˜, ë¦¬ë·°, DIY ë°©ë²• ë“±
- ë‰´ìŠ¤: ì‹œì‚¬ ì´ìŠˆ, ì‚¬íšŒ í˜„ìƒ, ê²½ì œ ë™í–¥ ë“±
""")

# ë„¤ì´ë²„ API ì •ë³´ ë° ë¬¸ì œí•´ê²°
st.sidebar.title("ë„¤ì´ë²„ API ì •ë³´")
st.sidebar.info("""
**API ìƒíƒœ:**
- Client ID: 9XhhxLV1IzDpTZagoBr1
- ë°ì´í„° ì¶œì²˜: ë„¤ì´ë²„ ê²€ìƒ‰ API

**ë¬¸ì œí•´ê²°:**
- API ì˜¤ë¥˜ ì‹œ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„
- ê²€ìƒ‰ì–´ë¥¼ ë‹¨ìˆœí•˜ê²Œ ë³€ê²½í•´ë³´ì„¸ìš”
- ë‹¤ë¥¸ ì†ŒìŠ¤ íƒ€ì…ìœ¼ë¡œ ì‹œë„í•´ë³´ì„¸ìš”
""")

# ì¶”ê°€ ë””ë²„ê¹… ì •ë³´ (ê°œë°œìš©)
st.sidebar.title("ë””ë²„ê¹… ì •ë³´")
if st.sidebar.checkbox("ë””ë²„ê¹… ëª¨ë“œ", value=False):
    st.sidebar.write(f"í˜„ì¬ ê²€ìƒ‰ ëª¨ë“œ: {search_mode}")
    st.sidebar.write(f"ì„ íƒëœ ì†ŒìŠ¤: {active_source_type}") # st.session_state.current_source_type
    st.sidebar.write(f"í˜„ì¬ ì¿¼ë¦¬: {query_to_use_in_search}") # st.session_state.query_input
    st.sidebar.write(f"ì‚¬ìš© ì¤‘ì¸ ì„ë² ë”© ëª¨ë¸: jhgan/ko-sroberta-multitask")
    
    st.sidebar.write("**API í‚¤ ìƒíƒœ:**")
    st.sidebar.write(f"- Supabase URL: {'âœ…' if supabase_url else 'âŒ'}")
    st.sidebar.write(f"- Supabase Key: {'âœ…' if supabase_key else 'âŒ'}")
    st.sidebar.write(f"- OpenAI Key: {'âœ…' if openai_api_key else 'âŒ'}")
    st.sidebar.write(f"- Naver Client ID: {'âœ…' if NAVER_CLIENT_ID else 'âŒ'}")
    st.sidebar.write(f"- Naver Client Secret: {'âœ…' if NAVER_CLIENT_SECRET else 'âŒ'}")
